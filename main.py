from fastapi import FastAPI, HTTPException, Response, Cookie, Depends
from fastapi.middleware.cors import CORSMiddleware
import asyncio
from concurrent.futures import ThreadPoolExecutor
from fastapi.responses import JSONResponse
import json
from pydantic import BaseModel
from pydantic import Field  # å†importå¯
from typing import Optional, List, Dict
import os
import time
from functools import wraps
import hashlib
from dotenv import load_dotenv
from pathlib import Path
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.schema import SystemMessage, HumanMessage
from langchain_core.documents import Document
import re as _re
import json as _json 

try:
    from pinecone import Pinecone
except Exception:
    Pinecone = None
import uuid
from datetime import datetime
try:
    from policy_agents import PolicyAgentSystem
except ImportError:
    PolicyAgentSystem = None

try:
    from flexible_policy_agents import FlexiblePolicyAgentSystem
except ImportError:
    FlexiblePolicyAgentSystem = None
import mysql.connector
from mysql.connector import Error

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆbackend/.env ã‚’æ˜ç¤ºçš„ã«å‚ç…§ï¼‰
ENV_PATH = Path(__file__).resolve().parent / ".env"
load_dotenv(dotenv_path=ENV_PATH, override=False)

app = FastAPI(title="AI Agent API", version="1.0.0")

# éåŒæœŸå‡¦ç†ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«
executor = ThreadPoolExecutor(max_workers=4)

# ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å®Ÿè£…
CACHE = {}
CACHE_TTL = 300  # 5åˆ†é–“ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥

def cache_key(*args, **kwargs):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
    key_string = str(args) + str(sorted(kwargs.items()))
    return hashlib.md5(key_string.encode()).hexdigest()

def memory_cache(ttl_seconds=CACHE_TTL):
    """ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            key = f"{func.__name__}_{cache_key(*args, **kwargs)}"
            current_time = time.time()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
            if key in CACHE:
                cached_data, timestamp = CACHE[key]
                if current_time - timestamp < ttl_seconds:
                    return cached_data
                else:
                    del CACHE[key]  # æœŸé™åˆ‡ã‚Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
            
            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            result = func(*args, **kwargs)
            CACHE[key] = (result, current_time)
            return result
        return wrapper
    return decorator

# UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ˜ç¤ºçš„ã«è¨­å®š
import sys
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
if hasattr(sys.stderr, 'reconfigure'):
    sys.stderr.reconfigure(encoding='utf-8')

origins = [
    # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã®ã‚ªãƒªã‚¸ãƒ³
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    # ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ã‚ªãƒªã‚¸ãƒ³
    "https://apps-junk-02.azurewebsites.net",
    # å¿…è¦ã«å¿œã˜ã¦ä»–ã®ã‚ªãƒªã‚¸ãƒ³ã‚’è¿½åŠ 
]

# CORSè¨­å®š - ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã¨Azureä¸¡å¯¾å¿œ
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º
        "http://localhost:3000",
        "http://localhost:3001", 
        "http://localhost:3002",
        "http://localhost:3003",
        "http://localhost:3004",
        "http://127.0.0.1:3000",
        "http://127.0.0.1:3001",
        "http://127.0.0.1:3002", 
        "http://127.0.0.1:3003",
        "http://127.0.0.1:3004",
        # Azure ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒï¼ˆå®Ÿéš›ã®URLï¼‰
        "https://apps-junk-02.azurewebsites.net",
        "https://aps-junk-01-fbgncnexhuekadft.canadacentral-01.azurewebsites.net",
        "https://apps-junk-01.azurewebsites.net",
    ],
    allow_origin_regex=r"https://.*\.azurewebsites\.net",  # Azureå‹•çš„URLãƒ‘ã‚¿ãƒ¼ãƒ³
    allow_credentials=True,  # ã‚¯ãƒƒã‚­ãƒ¼èªè¨¼ã«å¿…è¦
    allow_methods=["*"],
    allow_headers=["*"],
)

# ã‚«ã‚¹ã‚¿ãƒ JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆUTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¿è¨¼ï¼‰
class UTF8JSONResponse(JSONResponse):
    def __init__(self, content, **kwargs):
        kwargs.setdefault('media_type', 'application/json; charset=utf-8')
        super().__init__(content, **kwargs)

# ç’°å¢ƒå¤‰æ•°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "rag-hakusho")

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
embedding_model = None
chat = None
pc = None
index = None

if OPENAI_API_KEY:
    try:
        embedding_model = OpenAIEmbeddings(
            openai_api_key=OPENAI_API_KEY,
            model="text-embedding-3-small",
            chunk_size=1000,
        )
        
        chat = ChatOpenAI(
            openai_api_key=OPENAI_API_KEY,
            model="gpt-4o-mini",
            temperature=0.3,
        )
        print("âœ“ OpenAI models initialized successfully")
    except Exception as e:
        print(f"âš ï¸ Warning: OpenAI initialization failed: {e}")

if PINECONE_API_KEY and Pinecone:
    try:
        pc = Pinecone(api_key=PINECONE_API_KEY)
        index = pc.Index(INDEX_NAME)
        print("âœ“ Pinecone initialized successfully")
    except Exception as e:
        print(f"âš ï¸ Warning: Pinecone initialization failed: {e}")
else:
    print("âš ï¸ Warning: Pinecone not available")

if not OPENAI_API_KEY or not PINECONE_API_KEY:
    print("âš ï¸ Warning: Some AI services not available due to missing environment variables")
    print(f"   OPENAI_API_KEY: {'SET' if OPENAI_API_KEY else 'NOT SET'}")
    print(f"   PINECONE_API_KEY: {'SET' if PINECONE_API_KEY else 'NOT SET'}")
    print(f"   PINECONE_INDEX_NAME: {INDEX_NAME}")
    print("   ğŸ“‹ To fix this in Azure App Service:")
    print("   1. Go to Configuration â†’ Application settings")
    print("   2. Add OPENAI_API_KEY with your OpenAI API key")  
    print("   3. Add PINECONE_API_KEY with your Pinecone API key")
    print("   4. Add PINECONE_INDEX_NAME with your index name (default: rag-hakusho)")
    print("   5. Restart the app service")

# æ”¿ç­–ç«‹æ¡ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆAI ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
policy_system = None
flexible_policy_system = None

if chat and embedding_model and index and FlexiblePolicyAgentSystem:
    try:
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå¿…è¦
        try:
            from flexible_policy_agents import CrudSectionRepo, CrudChatRepo
        except ImportError:
            CrudSectionRepo = None
            CrudChatRepo = None
        
        # æ—¢å­˜ã®DBæ©Ÿèƒ½ã¨çµ±åˆã™ã‚‹ãŸã‚ã®CRUDã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼
        class MainCrud:
            def get_project_step_sections(self, project_id: str, step_key: str):
                try:
                    from DB.mysql_crud import get_project_step_sections
                    return get_project_step_sections(project_id, step_key)
                except:
                    return []
                    
            def get_recent_chat_messages(self, session_id: str, limit: int = 10):
                # ãƒãƒ£ãƒƒãƒˆå±¥æ­´æ©Ÿèƒ½ã¯å¾Œã§å®Ÿè£…
                return []
        
        main_crud = MainCrud()
        if CrudSectionRepo and CrudChatRepo:
            section_repo = CrudSectionRepo(main_crud)
            chat_repo = CrudChatRepo(main_crud)
        else:
            section_repo = None
            chat_repo = None
        
        if PolicyAgentSystem:
            policy_system = PolicyAgentSystem(chat, embedding_model, index)
        
        if FlexiblePolicyAgentSystem and section_repo and chat_repo:
            flexible_policy_system = FlexiblePolicyAgentSystem(chat, section_repo, chat_repo)
        print("âœ“ Policy agent systems initialized successfully")
    except Exception as e:
        print(f"âš ï¸ Warning: Policy agent initialization failed: {e}")
else:
    print("âš ï¸ Warning: Policy agents not available - AI services not initialized")

# =====================
# MySQL helpers
# =====================
def _mysql_config():
    return {
        'host': os.getenv('DB_HOST'),
        'port': int(os.getenv('DB_PORT', 3306)),
        'user': os.getenv('DB_USER'),
        'password': os.getenv('DB_PASSWORD'),
        'database': os.getenv('DB_NAME'),
        'charset': 'utf8mb4',
    }

def _execute_query(query: str, params: tuple | None = None):
    # ãƒ—ãƒ¼ãƒ«ã•ã‚ŒãŸæ¥ç¶šã‚’ä½¿ç”¨ï¼ˆå†åˆ©ç”¨ã«ã‚ˆã‚Šã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼‰
    config = _mysql_config()
    config.update({
        "buffered": True,
    })
    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    config.pop('prepared', None)
    config.pop('pool_name', None)
    config.pop('pool_size', None)
    config.pop('pool_reset_session', None)
    
    conn = mysql.connector.connect(**config)
    cur = conn.cursor(dictionary=True, buffered=True)
    try:
        cur.execute(query, params or ())
        if query.strip().upper().startswith('SELECT'):
            return cur.fetchall()
        conn.commit()
        return []
    finally:
        try:
            cur.close()
        finally:
            conn.close()

# Pydanticãƒ¢ãƒ‡ãƒ«
class MessageRequest(BaseModel):
    content: str
    search_type: Optional[str] = "normal"
    flow_step: Optional[str] = None
    context: Optional[dict] = None
    session_id: Optional[str] = None
    project_id: Optional[str] = None

class PolicyStepRequest(BaseModel):
    content: str
    step: str
    context: Optional[dict] = None

class PolicyStepResponse(BaseModel):
    id: str
    content: str
    step: str
    timestamp: str
    context: Optional[dict] = None

class FlexiblePolicyResponse(BaseModel):
    id: str
    content: str
    step: str
    timestamp: str
    session_id: str
    project_id: Optional[str] = None
    navigate_to: Optional[str] = None  # ã‚¹ãƒ†ãƒƒãƒ—ç§»å‹•ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    type: Optional[str] = None         # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ï¼ˆ"navigate"ç­‰ï¼‰
    full_state: Optional[dict] = None

class SessionStateResponse(BaseModel):
    session_id: str
    project_id: Optional[str] = None
    analysis_result: Optional[str] = None
    objective_result: Optional[str] = None
    concept_result: Optional[str] = None
    plan_result: Optional[str] = None
    proposal_result: Optional[str] = None
    last_updated_step: Optional[str] = None
    step_timestamps: Optional[dict] = None

class MessageResponse(BaseModel):
    id: str
    content: str
    type: str
    timestamp: str
    search_type: Optional[str] = None

class ChatSession(BaseModel):
    id: str
    title: str
    created_at: str
    updated_at: str

class ProjectStepSectionRequest(BaseModel):
    project_id: str
    step_key: str
    sections: List[Dict[str, str]]  # [{"section_key": "problem", "content": "..."}, ...]

class ProjectStepSectionResponse(BaseModel):
    id: str
    project_id: str
    step_key: str
    section_key: str
    content: str
    created_at: str
    updated_at: str

class CoworkerResponse(BaseModel):
    id: int
    name: str
    position: Optional[str] = None
    email: str
    department_name: Optional[str] = None

class ProjectCreateRequest(BaseModel):
    name: str
    description: Optional[str] = None
    owner_coworker_id: int
    member_ids: List[int] = []

class ProjectResponse(BaseModel):
    id: str
    name: str
    description: Optional[str] = None
    status: str
    owner_coworker_id: int
    owner_name: str
    members: List[CoworkerResponse]
    created_at: str
    updated_at: str

# CRUDæ“ä½œã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from DB.mysql_crud import (
    search_coworkers,
    create_project,
    get_project_by_id,
    get_projects_by_coworker,
    save_project_step_sections,
    get_project_step_sections,
    health_check as db_health_check,
    CRUDError
)

# èªè¨¼é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from auth import auth_service, LoginRequest, LoginResponse

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
sessions = {}

# =====================
# DB utility functions
# =====================
def _get_step_id(project_id: Optional[str], step_key: Optional[str]) -> Optional[str]:
    if not project_id or not step_key:
        return None
    rows = _execute_query(
        "SELECT id FROM policy_steps WHERE project_id = %s AND step_key = %s",
        (project_id, step_key),
    )
    if rows:
        return rows[0]['id']
    # ãªã‘ã‚Œã°ä½œæˆ
    new_id = str(uuid.uuid4())
    _execute_query(
        """
        INSERT INTO policy_steps (id, project_id, step_key, step_name, order_no, status)
        VALUES (%s, %s, %s, %s, 1, 'active')
        """,
        (new_id, project_id, step_key, step_key.title()),
    )
    return new_id

def _ensure_chat_session(session_id: str, project_id: Optional[str], step_key: Optional[str]) -> tuple[str, Optional[str]]:
    """chat_sessions ã«å­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆã—ã¦ session_id ã¨ step_id ã‚’è¿”ã™"""
    # ã‚¹ã‚­ãƒ¼ãƒä¸Š project_id ã¯ NOT NULL ãªã®ã§ã€æœªæŒ‡å®šãªã‚‰DBä¿å­˜ã¯ã‚¹ã‚­ãƒƒãƒ—
    if not project_id:
        return session_id, None
    step_id = _get_step_id(project_id, step_key) if (project_id and step_key) else None
    _execute_query(
        """
        INSERT IGNORE INTO chat_sessions (id, project_id, step_id, title, created_by, created_at, updated_at)
        VALUES (%s, %s, %s, NULL, NULL, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        """,
        (session_id, project_id, step_id),
    )
    return session_id, step_id

def _save_chat_message(session_id: str, project_id: Optional[str], step_id: Optional[str], role: str, msg_type: str, content: str) -> None:
    # project_id ãŒç„¡ã„å ´åˆã¯ä¿å­˜ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¹ã‚­ãƒ¼ãƒã§ NOT NULLï¼‰
    if not project_id:
        return
    _execute_query(
        """
        INSERT INTO chat_messages (id, session_id, project_id, step_id, role, msg_type, content, created_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
        """,
        (str(uuid.uuid4()), session_id, project_id, step_id, role, msg_type, content),
    )

def rerank_documents(query: str, docs: list[Document], chat: ChatOpenAI, top_k: int = 5) -> list[Document]:
    """æ–‡æ›¸ã®å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
    prompt = PromptTemplate(
        input_variables=["query", "documents", "top_k"],
        template="""
ã‚ãªãŸã¯å„ªç§€ãªæ”¿ç­–ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ã€ãã®é–¢é€£ã¨ã—ã¦æ¤œç´¢ã•ã‚ŒãŸæ–‡æ›¸ã®ãƒªã‚¹ãƒˆã§ã™ã€‚
è³ªå•ã«æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ä¸Šä½{top_k}ä»¶ã®æ–‡æ›¸ã‚’é¸ã³ã€ç•ªå·ã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

è³ªå•: {query}

æ–‡æ›¸ä¸€è¦§:
{documents}

å‡ºåŠ›å½¢å¼ï¼ˆæ–‡æ›¸ç•ªå·ã®ã¿ã€ä¾‹: 0,2,4ï¼‰:
"""
)

    
    numbered_docs = []
    for i, doc in enumerate(docs):
        cleaned = doc.page_content[:200].replace("\n", " ")
        numbered_docs.append(f"{i}: {cleaned}")

    docs_text = "\n".join(numbered_docs)

    msg = HumanMessage(content=prompt.format(query=query, documents=docs_text, top_k=top_k))
    response = chat.invoke([msg])
    selected = []
    for s in response.content.split(","):
        try:
            idx = int(s.strip())
            if 0 <= idx < len(docs):
                selected.append(docs[idx])
        except:
            continue
    return selected

@app.get("/")
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"message": "AI Agent API is running"}

if __name__ == "__main__":
    import uvicorn
    import os
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)

# =====================
# èªè¨¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================

@app.post("/api/auth/login", response_model=LoginResponse)
async def login_endpoint(request: LoginRequest, response: Response):
    """ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        return await auth_service.login(request, response)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/auth/logout")
async def logout_endpoint(response: Response):
    """ãƒ­ã‚°ã‚¢ã‚¦ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        await auth_service.logout(response)
        return {"message": "Successfully logged out"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/auth/me")
async def get_current_user_endpoint(access_token: str = Cookie(None)):
    """ç¾åœ¨ã®ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—"""
    try:
        user = await auth_service.get_current_user(access_token)
        if not user:
            raise HTTPException(status_code=401, detail="èªè¨¼ãŒå¿…è¦ã§ã™")
        return user
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/auth/verify")
async def verify_token_endpoint(access_token: str = Cookie(None)):
    """ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèª"""
    try:
        user = await auth_service.get_current_user(access_token)
        if not user:
            return {"valid": False}
        return {"valid": True, "user": user}
    except Exception as e:
        return {"valid": False, "error": str(e)}
    
# =====================
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================

@app.post("/api/projects", response_model=ProjectResponse)
async def create_project_endpoint(request: ProjectCreateRequest):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ"""
    try:
        project = create_project(
            request.name, 
            request.description or "", 
            request.owner_coworker_id, 
            request.member_ids
        )
        if not project:
            raise HTTPException(status_code=400, detail="Failed to create project")
        
        return UTF8JSONResponse(ProjectResponse(**project).dict())
    except CRUDError as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
@app.get("/api/coworkers/search", response_model=List[CoworkerResponse])
async def search_coworkers_endpoint(q: str = "", department: str = ""):
    """coworkersæ¤œç´¢"""
    try:
        coworkers = search_coworkers(q, department)
        return UTF8JSONResponse([CoworkerResponse(**coworker).dict() for coworker in coworkers])
    except CRUDError as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
@app.get("/api/projects/{project_id}", response_model=ProjectResponse)
async def get_project_endpoint(project_id: str):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©³ç´°å–å¾—"""
    try:
        project = get_project_by_id(project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        
        return UTF8JSONResponse(ProjectResponse(**project).dict())
    except CRUDError as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/projects/by-coworker/{coworker_id}", response_model=List[ProjectResponse])
async def get_projects_by_coworker_endpoint(coworker_id: int):
    """coworkerãŒå‚åŠ ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§å–å¾—"""
    try:
        projects = get_projects_by_coworker(coworker_id)
        return UTF8JSONResponse([ProjectResponse(**project).dict() for project in projects])
    except CRUDError as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
# =====================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================

@app.get("/api/session-state/{session_id}", response_model=SessionStateResponse)
async def get_session_state(session_id: str):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å–å¾—"""
    try:
        state = flexible_policy_system.get_session_state(session_id)
        
        if "error" in state:
            raise HTTPException(status_code=404, detail=state["error"])
        
        return SessionStateResponse(**state)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/sessions", response_model=List[ChatSession])
async def get_sessions():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—"""
    return list(sessions.values())

@app.post("/api/sessions", response_model=ChatSession)
async def create_session():
    """æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    session_id = str(uuid.uuid4())
    now = datetime.now()
    
    session = ChatSession(
        id=session_id,
        title=f"æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ {now.strftime('%Y-%m-%d %H:%M')}",
        created_at=now.isoformat(),
        updated_at=now.isoformat()
    )
    
    sessions[session_id] = session
    return session

@app.post("/api/project-step-sections", response_model=List[ProjectStepSectionResponse])
async def save_step_sections(request: ProjectStepSectionRequest):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒ†ãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜"""
    try:
        print(f"DEBUG: Received request: project_id={request.project_id}, step_key={request.step_key}, sections_count={len(request.sections)}")
        print(f"DEBUG: Request sections: {request.sections}")
        
        saved_sections = save_project_step_sections(request.project_id, request.step_key, request.sections)
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¿å­˜å¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
        try:
            from DB.mysql_crud import invalidate_project_cache
            invalidate_project_cache(request.project_id)
        except Exception as e:
            print(f"Warning: Cache invalidation failed: {e}")
        
        print(f"DEBUG: Successfully saved {len(saved_sections)} sections")
        return UTF8JSONResponse([ProjectStepSectionResponse(**section).dict() for section in saved_sections])
    except CRUDError as e:
        print(f"DEBUG: CRUDError occurred: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        print(f"DEBUG: Exception occurred: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/project-step-sections/{project_id}/{step_key}", response_model=List[ProjectStepSectionResponse])
async def get_step_sections(project_id: str, step_key: str):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒ†ãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
    try:
        sections = get_project_step_sections(project_id, step_key)
        return UTF8JSONResponse([ProjectStepSectionResponse(**section).dict() for section in sections])
    except CRUDError as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/project-all-sections/{project_id}")
async def get_project_all_sections_endpoint(project_id: str):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¸€æ‹¬å–å¾—ï¼ˆé«˜é€ŸåŒ–ï¼‰"""
    try:
        from DB.mysql_crud import MySQLCRUD
        crud = MySQLCRUD()
        sections_by_step = crud.get_project_all_step_sections(project_id)
        return UTF8JSONResponse(sections_by_step)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
# =====================
# ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================

@app.post("/api/chat", response_model=MessageResponse)
async def chat_endpoint(request: MessageRequest):
    """ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        # DBä¿å­˜: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        sid = request.session_id or str(uuid.uuid4())
        session_id, step_id = _ensure_chat_session(sid, request.project_id, request.flow_step)
        _save_chat_message(session_id, request.project_id, step_id, 'user', request.search_type or 'normal', request.content)

        # 1. RAGæ¤œç´¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã‚’æœ€å„ªå…ˆã§å‡¦ç†
        if request.search_type == "fact":
            if not (embedding_model and index):
                ai_content = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨RAGæ¤œç´¢æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                sources = []
            else:
                ai_content, sources = perform_rag_search(request.content)
            
            if request.session_id and flexible_policy_system and hasattr(flexible_policy_system, "add_fact_search_result"):
                try:
                    flexible_policy_system.add_fact_search_result(request.session_id, ai_content)
                except Exception as e:
                    print(f"Warning: Failed to add fact search result: {e}")

            # RAGçµæœã‚’DBã«ä¿å­˜ï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªï¼‹å‡ºå…¸ï¼‰
            try:
                session_id, step_id = _ensure_chat_session(sid, request.project_id, request.flow_step)
                # rag_search_results ã¯ project_id, step_id ãŒ NOT NULL ã®ãŸã‚ã€æƒã£ã¦ã„ã‚‹æ™‚ã®ã¿ä¿å­˜
                if request.project_id and step_id:
                    _execute_query(
                        """
                        INSERT INTO rag_search_results
                          (id, project_id, step_id, session_id, query, result_text, result_json, sources_json, created_by, created_at)
                        VALUES
                          (%s, %s, %s, %s, %s, %s, NULL, %s, NULL, CURRENT_TIMESTAMP)
                        """,
                        (
                            str(uuid.uuid4()),
                            request.project_id,
                            step_id,
                            session_id,
                            request.content,
                            ai_content,
                            json.dumps(sources, ensure_ascii=False),
                        ),
                    )
            except Exception as e:
                print(f"WARN: failed to save rag_search_results: {e}")

        # 2. æ”¿ç­–ç«‹æ¡ˆã‚¹ãƒ†ãƒƒãƒ—ã®ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆ
        elif request.flow_step:
            if not flexible_policy_system:
                ai_content = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨æ”¿ç­–ç«‹æ¡ˆæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            else:
                session_id = request.session_id or str(uuid.uuid4())
                project_id = request.project_id
                
                try:
                    result = flexible_policy_system.process_flexible(
                        request.content,
                        session_id,
                        request.flow_step,
                        project_id
                    )
                except Exception as e:
                    print(f"Error in flexible_policy_system.process_flexible: {e}")
                    result = {"error": "æ”¿ç­–ç«‹æ¡ˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"}
                
                if "error" in result:
                    ai_content = result["error"]
                else:
                    ai_content = result["result"]
            
        # 3. ãã®ä»–ï¼ˆäººè„ˆæ¤œç´¢ã€é€šå¸¸ã®ãƒãƒ£ãƒƒãƒˆãªã©ï¼‰
        elif request.search_type == "network":
            if not chat:
                ai_content = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            else:
                ai_content = perform_normal_chat(request.content)
        else:
            if not chat:
                ai_content = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            else:
                ai_content = perform_normal_chat(request.content, request.session_id)
        
        ai_message = MessageResponse(
            id=str(uuid.uuid4()),
            content=ai_content,
            type="ai",
            timestamp=datetime.now().isoformat(),
            search_type=request.search_type
        )
        # DBä¿å­˜: AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        _save_chat_message(session_id, request.project_id, step_id, 'ai', request.search_type or 'normal', ai_content)
        
        return UTF8JSONResponse(ai_message.dict())
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
# =====================
# ãƒãƒ£ãƒƒãƒˆï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================

@app.post("/api/policy-flexible", response_model=FlexiblePolicyResponse)
async def flexible_policy_endpoint(request: MessageRequest):
    """æŸ”è»Ÿãªæ”¿ç­–ç«‹æ¡ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        if not request.flow_step:
            raise HTTPException(status_code=400, detail="flow_step is required")
        
        if not flexible_policy_system:
            raise HTTPException(status_code=503, detail="Policy system not available. Please check environment configuration.")
        
        session_id = request.session_id or str(uuid.uuid4())
        project_id = request.project_id
        
        try:
            result = flexible_policy_system.process_flexible(
                request.content,
                session_id,
                request.flow_step,
                project_id
            )
        except Exception as e:
            print(f"Error in flexible_policy_system.process_flexible: {e}")
            raise HTTPException(status_code=500, detail="æ”¿ç­–ç«‹æ¡ˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
        if "error" in result:
            raise HTTPException(status_code=400, detail=result["error"])
        
        response = FlexiblePolicyResponse(
            id=str(uuid.uuid4()),
            content=result["result"],
            step=result["step"],
            timestamp=datetime.now().isoformat(),
            session_id=session_id,
            project_id=project_id,
            navigate_to=result.get("navigate_to"),  # ã‚¹ãƒ†ãƒƒãƒ—ç§»å‹•æƒ…å ±
            type=result.get("type"),                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ—
            full_state=result["full_state"]
        )

        # DBä¿å­˜: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¢ºä¿ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
        session_id, step_id = _ensure_chat_session(session_id, project_id, request.flow_step)
        _save_chat_message(session_id, project_id, step_id, 'user', 'normal', request.content)
        _save_chat_message(session_id, project_id, step_id, 'ai', 'normal', result["result"]) 
        
        return UTF8JSONResponse(response.dict())
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
# =====================
# ãƒãƒ£ãƒƒãƒˆï¼ˆRAGï¼‰ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================

@memory_cache(ttl_seconds=600)  # 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def perform_rag_search(query: str) -> tuple[str, list[dict]]:
    """RAGæ¤œç´¢ã‚’å®Ÿè¡Œã—ã€å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã¨å‡ºå…¸ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    try:
        if not embedding_model or not index:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨RAGæ¤œç´¢æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", []
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®šã—ã¦embeddingç”Ÿæˆæ™‚é–“ã‚’åˆ¶é™
        query_embedding = embedding_model.embed_query(query)
        
        results = index.query(vector=query_embedding, top_k=15, include_metadata=True)

        matches = results.matches if hasattr(results, "matches") else results.get("matches", [])
        initial_docs = []
        for m in matches:
            meta  = m.metadata if hasattr(m, "metadata") else m.get("metadata", {}) or {}
            score = m.score    if hasattr(m, "score")    else m.get("score")
            text  = meta.get("text") or meta.get("chunk") or meta.get("page_content") or ""
            if not text:
                continue
            doc = Document(
                page_content=text,
                metadata={
                    "source": meta.get("source", ""),
                    "figure_section": meta.get("figure_section", ""),
                    "chunk_index": meta.get("chunk_index", ""),
                    "page_number": meta.get("page_number", ""),
                    "section_title": meta.get("section_title", ""),
                    "document_title": meta.get("document_title", ""),
                    "year": meta.get("year", ""),
                    "score": score,
                },
            )
            initial_docs.append(doc)


        # å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        top_docs = rerank_documents(query, initial_docs, chat, top_k=5)

        # LLMã«å›ç­”ç”Ÿæˆã¨å‡ºå…¸æƒ…å ±ã®åŸ‹ã‚è¾¼ã¿ã‚’ä¾é ¼
        documents_string = ""
        for i, doc in enumerate(top_docs, 1):
            # å‡ºå…¸åã‚’æ§‹ç¯‰
            source_name = doc.metadata.get('document_title', 'ä¸æ˜')
            year = doc.metadata.get('year', '')
            section = doc.metadata.get('section_title', '')
            
            # å‡ºå…¸æƒ…å ±ã‚’ã€Œã€æ–‡æ›¸å(å¹´) - ç« ç¯€ã€‘ã€ã®å½¢å¼ã§ã¾ã¨ã‚ã‚‹
            source_info = f"ã€{source_name}"
            if year:
                source_info += f"ï¼ˆ{year}å¹´åº¦ï¼‰"
            if section:
                source_info += f" - {section}"
            source_info += "ã€‘"

            documents_string += f"{source_info}\n{doc.page_content.strip()}\n\n"

        prompt = PromptTemplate(
            template="""ã‚ãªãŸã¯æ€è€ƒæ•´ç†ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å£æ‰“ã¡ç›¸æ‰‹ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã¨ã€ãã‚Œã«é–¢é€£ã™ã‚‹è¤‡æ•°ã®å‚ç…§è³‡æ–™ãŒæä¾›ã•ã‚Œã¾ã™ã€‚
ã“ã‚Œã‚‰ã®è³‡æ–™ã‚’æ´»ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å¿œç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åŸºæœ¬ãƒ«ãƒ¼ãƒ«ã€‘
- å‚ç…§è³‡æ–™å†…ã®æƒ…å ±ã‚’è¦ç´„ã—ã¦ã€è‡ªç„¶ãªæ–‡ç« ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
- **å¿…ãš**æœ¬æ–‡ä¸­ã®è©²å½“ã™ã‚‹ç®‡æ‰€ã«**æä¾›ã•ã‚ŒãŸå½¢å¼ã®å‡ºå…¸æƒ…å ±ï¼ˆä¾‹ï¼šã€ã€‡ã€‡ç™½æ›¸ - ç¬¬3ç« ã€‘ï¼‰ã‚’ä»˜ä¸**ã—ã¦ãã ã•ã„ã€‚
- å‚ç…§è³‡æ–™ã«è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„æ¨æ¸¬ã‚„ä¸€èˆ¬çš„ãªçŸ¥è­˜ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
- å›ç­”ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è€ƒãˆã‚’å¼•ãå‡ºã™ã‚ˆã†ãªå•ã„ã‹ã‘ã§ç· ã‚ããã£ã¦ãã ã•ã„ã€‚

ã€å‚ç…§è³‡æ–™ã€‘
{documents}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã€‘
{query}

ã€å›ç­”ã€‘
""",
            input_variables=["documents", "query"]
        )

        messages = [
            SystemMessage(content="ã‚ãªãŸã¯æ€è€ƒæ•´ç†ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å£æ‰“ã¡ç›¸æ‰‹ã§ã™ã€‚å›ç­”ã®æœ¬æ–‡ä¸­ã«å‚ç…§è³‡æ–™ã®æƒ…å ±ã‚’ç›´æ¥å¼•ç”¨ã—ã€äº‹å®Ÿã«åŸºã¥ã„ãŸå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"),
            HumanMessage(content=prompt.format(documents=documents_string, query=query))
        ]

        response = chat.invoke(messages)

        # å‡ºå…¸æƒ…å ±ã®é…åˆ—ã‚’æ§‹ç¯‰
        sources: list[dict] = []
        for doc in top_docs:
            sources.append({
                "source": doc.metadata.get("source"),
                "section_title": doc.metadata.get("section_title"),
                "document_title": doc.metadata.get("document_title"),
                "year": doc.metadata.get("year"),
                "page_number": doc.metadata.get("page_number"),
                "score": doc.metadata.get("score"),
            })

        return response.content.strip(), sources
        
    except Exception as e:
        return f"RAGæ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}", []

def perform_policy_step(content: str, step: str, context: dict = None) -> str:
    """æ”¿ç­–ç«‹æ¡ˆã‚¹ãƒ†ãƒƒãƒ—åˆ¥å‡¦ç†"""
    try:
        if not policy_system:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨æ”¿ç­–ç«‹æ¡ˆæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        
        result = policy_system.process_step(step, content, context)
        return result
    except Exception as e:
        return f"æ”¿ç­–ç«‹æ¡ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def perform_normal_chat(content: str, session_id: str = None) -> str:
    """é€šå¸¸ã®ãƒãƒ£ãƒƒãƒˆï¼ˆè‡ªç„¶ãªå¯¾è©±å‹å£æ‰“ã¡ç›¸æ‰‹ï¼‰"""
    try:
        if not chat:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        
        fact_context = ""
        if session_id and flexible_policy_system:
            try:
                session_state = flexible_policy_system._get_session_state(session_id)
                if session_state and session_state.get("fact_search_results"):
                    recent_facts = "\\n\\n".join(session_state["fact_search_results"][-2:])
                    fact_context = f"\\n\\nã€ã“ã‚Œã¾ã§ã®ãƒ•ã‚¡ã‚¯ãƒˆæ¤œç´¢çµæœã€‘\\n{recent_facts}"
            except Exception as e:
                print(f"Warning: Failed to get session state: {e}")

        user_input_with_context = content + fact_context if fact_context else content
        
        messages = [
            SystemMessage(content="""ã‚ãªãŸã¯æ€è€ƒæ•´ç†ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å£æ‰“ã¡ç›¸æ‰‹ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®è‡ªç„¶ãªå¯¾è©±ã‚’é€šã˜ã¦ã€ä»¥ä¸‹ã®å½¹å‰²ã‚’æœãŸã—ã¦ãã ã•ã„ï¼š
...ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯å¤‰æ›´ãªã—ï¼‰...
"""),
            HumanMessage(content=user_input_with_context)
        ]
        
        response = chat.invoke(messages)
        return response.content.strip()
        
    except Exception as e:
        return f"ãƒãƒ£ãƒƒãƒˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    

# =====================
# äººè„ˆæ¤œç´¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# =====================

# LLM ã«ä½¿ã‚ã›ã¦ã‚ˆã„ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã‚«ãƒ©ãƒ ã‚’æ˜ç¤ºï¼ˆã“ã‚Œä»¥å¤–ã¯ä¸å¯ï¼‰
ALLOWED_TABLES = {
    "business_cards": [
        "id", "name", "company", "department", "position", "memo",
        "owner_coworker_id", "corporate_number", "company_id"
    ],
    "companies": [
        "id", "name", "corporate_number", "postal_code", "location",
        "company_type", "founding_date", "capital", "employee_number",
        "business_summary", "update_date"
    ],
    "coworker_relations": [
        "coworker_id", "business_card_id", "first_contact_date",
        "last_contact_date", "contact_count"
    ],
}

# å½¹ã«ç«‹ãŸãªã„æ±ç”¨èªï¼ˆWHEREã«å…¥ã‚‹ã¨0ä»¶ã«ãªã‚Šã‚„ã™ã„èªã‚’æ‹¡å……ï¼‰
GENERIC_TOKENS: set[str] = {
    "ç¤¾å“¡", "æ‹…å½“è€…", "å¾“æ¥­å“¡", "å½¹è·", "è·ç¨®", "éƒ¨é–€", "éƒ¨ç½²",
    "ä¼šç¤¾", "ä¼æ¥­", "æ—¥æœ¬", "å›½å†…", "æµ·å¤–", "æœ¬ç¤¾",
    # æ¥­ç¨®ãƒ»æ¥­ç•Œç³»ï¼ˆbc.department ã«èª¤ã£ã¦å…¥ã‚ŒãŒã¡ï¼‰
    "æ¥­ç¨®", "æ¥­ç•Œ", "å°å£²", "å°å£²æ¥­", "ã‚µãƒ¼ãƒ“ã‚¹æ¥­", "ãƒ¡ãƒ¼ã‚«ãƒ¼", "è£½é€ æ¥­", "ITæ¥­ç•Œ"
}

def _cleanup_nl_query(q: str) -> str:
    """
    è‡ªç„¶æ–‡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ­£è¦åŒ–:
    - / ãƒ»ã€ãƒ»,ãƒ»ç©ºç™½ã§åˆ†å‰²ï¼ˆå…¨è§’ç©ºç™½ã‚‚åŠè§’ã«ï¼‰
    - æ±ç”¨èª/æ¥­ç¨®èªã‚’é™¤å»
    - é‡è¤‡æ’é™¤ï¼ˆé †åºã¯ç¶­æŒï¼‰
    ä¾‹: 'ä»»å¤©å ‚/ã‚²ãƒ¼ãƒ /æ—¥æœ¬/å½¹è·/éƒ¨é–€/ç¤¾å“¡' -> 'ä»»å¤©å ‚ ã‚²ãƒ¼ãƒ '
    """
    q = (q or "").replace("ã€€", " ")  # å…¨è§’ç©ºç™½â†’åŠè§’
    q = q.replace("ï¼", "/").replace("ã€", "/").replace(",", "/")
    parts = [p.strip() for p in re.split(r"[\/\s]+", q) if p.strip()]
    parts = [p for p in parts if p not in GENERIC_TOKENS]
    seen: set[str] = set()
    cleaned: list[str] = []
    for p in parts:
        if p not in seen:
            seen.add(p)
            cleaned.append(p)
    return " ".join(cleaned) if cleaned else (q.strip() or "")



# --- DB2 (junk_db) å‘ã‘ã®æ¥ç¶šãƒ˜ãƒ«ãƒ‘ï¼ˆäººç‰©æ¤œç´¢å°‚ç”¨ï¼‰ ---
def _mysql_config_db2():
    return {
        'host': os.getenv('DB_HOST2'),
        'port': int(os.getenv('DB_PORT2', 3306)),
        'user': os.getenv('DB_USER2'),
        'password': os.getenv('DB_PASSWORD2'),
        'database': os.getenv('DB_NAME2'),
        'ssl_ca': os.getenv('DB_SSL_CA_PATH2'),
        'charset': 'utf8mb4',
        'autocommit': True,
    }

def _execute_query_db2(query: str, params: tuple | None = None):
    cfg = _mysql_config_db2()
    connect_kwargs = dict(
        host=cfg['host'],
        port=cfg['port'],
        user=cfg['user'],
        password=cfg['password'],
        database=cfg['database'],
        charset=cfg.get('charset', 'utf8mb4'),
        autocommit=cfg.get('autocommit', True),
        use_pure=True,
    )
    if cfg.get('ssl_ca'):
        connect_kwargs['ssl_ca'] = cfg['ssl_ca']
    conn = mysql.connector.connect(**connect_kwargs)
    cur = conn.cursor(dictionary=True)
    try:
        cur.execute(query, params or ())
        if query.strip().upper().startswith('SELECT'):
            return cur.fetchall()
        conn.commit()
        return []
    finally:
        try:
            cur.close()
        finally:
            conn.close()

# --- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ï¼ˆä¸­å¿ƒ=ååˆºã€å¤–å‘¨=ååˆºä¿æœ‰è€…ï¼‰ -----------------
def _get_network_for_card(card_id: int) -> dict:
    # ä¸­å¿ƒï¼ˆååˆºï¼‰
    sql_center = """
        SELECT bc.id, bc.name, COALESCE(bc.company, c.name) AS company
        FROM business_cards bc
        LEFT JOIN companies c ON c.id = bc.company_id
        WHERE bc.id = %s
    """
    rows = _execute_query_db2(sql_center, (card_id,))
    if not rows:
        raise HTTPException(status_code=404, detail="business_card not found")
    center = rows[0]
    center_id = f"card:{center['id']}"
    nodes = [{"id": center_id, "label": f"{center['name']}", "kind": "ä¸­å¿ƒ"}]
    edges = []

    # ååˆºã‚’ä¿æœ‰ã—ã¦ã„ã‚‹ç¤¾å†…ãƒ¡ãƒ³ãƒãƒ¼
    sql_holders = """
        SELECT cw.id AS coworker_id, cw.name AS coworker_name, d.name AS dept,
               cr.first_contact_date, cr.last_contact_date, cr.contact_count
        FROM coworker_relations cr
        JOIN coworkers cw       ON cw.id = cr.coworker_id
        LEFT JOIN departments d ON d.id = cw.department_id
        WHERE cr.business_card_id = %s
        ORDER BY COALESCE(cr.last_contact_date, cr.first_contact_date) DESC, cw.name
    """
    holders = _execute_query_db2(sql_holders, (card_id,))
    for h in holders:
        nid = f"cw:{h['coworker_id']}"
        label = f"{h['coworker_name']}" + (f"\n{h['dept']}" if h.get("dept") else "")
        nodes.append({"id": nid, "label": label, "kind": "ååˆºä¿æœ‰è€…"})
        edges.append({"source": center_id, "target": nid, "label": "ååˆºä¿æœ‰è€…"})

    return {"nodes": nodes, "edges": edges}


# ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆç”ŸæˆSQLã‚’è¿”ã™ï¼‰
PEOPLE_SQL_DEBUG  = os.getenv("PEOPLE_SQL_DEBUG", "0") == "1"

class PeopleSearchRequest(BaseModel):
    query: str = Field(..., description="è‡ªç„¶æ–‡ã®æ¤œç´¢æ¡ä»¶ï¼ˆä¾‹ï¼š'å¯Œå±± EC ãƒ‡ã‚¶ã‚¤ãƒ³'ï¼‰")
    top_k: int = Field(5, ge=1, le=50, description="æœ€å¤§ä»¶æ•°")
    coworker_id: int | None = Field(None, description="å„ªå…ˆã—ãŸã„åŒåƒšã®IDï¼ˆä»»æ„ï¼‰")

def _people_generate_sql_with_llm(
    nl_query: str,
    top_k: int,
    coworker_id: int | None,
    force_single_select: bool = False,
    force_template: bool = False,
) -> str:
    """
    æ—¥æœ¬èªâ†’MySQL SELECT ã‚’1æ–‡ã ã‘ç”Ÿæˆã€‚å¿…è¦ã«å¿œã˜ã¦ JOINã€‚
    force_single_select: ã€ŒSELECT ã¯1å›ã ã‘ã€ã¨å¼·ãåˆ¶ç´„
    force_template: SELECT â€¦ FROM business_cards bc â€¦ LIMIT n ã®å½¢ã‚’å¼·åˆ¶
    """
    if not chat:
        raise HTTPException(status_code=500, detail="OpenAI (chat) ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # ã‚¹ã‚­ãƒ¼ãƒã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸
    schema_desc = []
    for tbl, cols in ALLOWED_TABLES.items():
        schema_desc.append(f"- {tbl}({', '.join(cols)})")
    schema_text = "\n".join(schema_desc)

    rules = [
        # â† æ˜ç¢ºã«ã€ŒSELECT ã¯1å›ã ã‘ã€ã‚’å®£è¨€ï¼ˆå˜èªãƒ¬ãƒ™ãƒ«ï¼‰
        "Generate EXACTLY ONE SELECT statement only. The word SELECT must appear EXACTLY ONCE.",
        # â† ã‚µãƒ–ã‚¯ã‚¨ãƒªå…¨é¢ç¦æ­¢ã‚’ â€œ(SELECT â€¦)â€ ã¾ã§åæŒ‡ã—ã§æ˜ç¤º
        "NO subqueries of any kind: NO EXISTS(...), NO IN (SELECT ...), NO (SELECT ...) in any expression, NO CTEs, NO UNION.",
        "The main table MUST be business_cards (alias bc).",
        "Use LEFT JOIN companies c ON c.id = bc.company_id when needed.",
        "Use LEFT JOIN coworker_relations cr ON cr.business_card_id = bc.id when needed.",
        "Use only allowed columns. Return these aliases: id, name, company, department, title, avatar_url, score",
        "company := COALESCE(c.name, bc.company), title := COALESCE(bc.title, bc.position)",
        "ALWAYS ORDER BY score DESC, id ASC.",
        "ALWAYS include LIMIT (the number will be overwritten later).",
        'Output MUST be a single JSON object: {"sql": "..."} . No extra text, no code fences.',
        # æ–‡å­—åˆ—æ¯”è¼ƒã¯å¸¸ã«éƒ¨åˆ†ä¸€è‡´ã§
        "All text filters MUST use LIKE with wildcards: LIKE CONCAT('%', <keyword>, '%'). "
        "Never use equality (=) for company names or titles.",
        # ä¼šç¤¾åã®ã‚†ã‚‰ãå¯¾ç­–ï¼ˆâ€œæ ªå¼ä¼šç¤¾â€â€œ(æ ª)â€ã‚„ç©ºç™½ã‚’ç„¡è¦–ï¼‰
        "When matching company names, normalize by stripping 'æ ªå¼ä¼šç¤¾', '(æ ª)', and spaces using "
        "REPLACE(REPLACE(REPLACE(COALESCE(c.name, bc.company),'æ ªå¼ä¼šç¤¾',''),'(æ ª)',''),' ',''). "
        "Compare that normalized value with LIKE CONCAT('%', <company_keyword>, '%').",
            # â˜… ã“ã“ã‚’æ–°è¦è¿½åŠ ï¼šæ¥­ç¨®èªã¯ç„¡è¦–ã™ã‚‹æŒ‡ç¤º
        "Industry/sector words (e.g., å°å£²æ¥­, è£½é€ æ¥­, ITæ¥­ç•Œ) MUST NOT be mapped to bc.department; "
        "bc.department is an internal team like å–¶æ¥­éƒ¨/é–‹ç™ºéƒ¨. If the user mentions an industry, ignore that condition."
    ]
    if force_single_select:
        rules.insert(0, "The word SELECT must appear EXACTLY ONCE in the whole statement.")
    if force_template:
        rules.insert(0, "Your SQL MUST match this shape strictly: "
                        "SELECT <columns> FROM business_cards bc"
                        "[ LEFT JOIN <table> <alias> ON <cond> ]*"
                        "[ WHERE <conditions> ]* ORDER BY <expr> LIMIT <n>")

    system = (
        "You are a strict SQL generator for MySQL 8.\n"
        f"Allowed tables and columns:\n{schema_text}\n\n"
        "Rules:\n- " + "\n- ".join(rules) + "\n"
    )

    hints = []
    if coworker_id is not None:
        hints.append(
            f"Prefer or filter by coworker_relations.coworker_id = {coworker_id} "
            "(e.g., add COALESCE(cr.contact_count,0) to score)."
        )
    hints_text = ("\nHints:\n- " + "\n- ".join(hints)) if hints else ""

    example = (
        "{\n"
        "  \"sql\": \"SELECT bc.id AS id, bc.name AS name,\n"
        "                  COALESCE(c.name, bc.company) AS company,\n"
        "                  bc.department AS department,\n"
        "                  COALESCE(bc.title, bc.position) AS title,\n"
        "                  bc.avatar_url AS avatar_url,\n"
        "                  (COALESCE(cr.contact_count,0)) AS score\n"
        "           FROM business_cards bc\n"
        "           LEFT JOIN companies c ON c.id = bc.company_id\n"
        "           LEFT JOIN coworker_relations cr ON cr.business_card_id = bc.id\n"
        "           ORDER BY score DESC, id ASC LIMIT 5\"\n"
        "}"
    )

    user = (
        "User intent (Japanese natural language):\n"
        f"{nl_query}\n\n"
        f"{hints_text}\n"
        "Write the query WITHOUT any subqueries; if you think you need EXISTS/IN, "
        "always rewrite it using LEFT JOIN + WHERE or JOIN-based scoring.\n"
        "Return JSON only, for example:\n" + example
    )

    resp = chat.invoke([SystemMessage(content=system), HumanMessage(content=user)])
    content_text = str(resp.content).strip()

    m = _re.search(r"\{[\s\S]*\}", content_text)
    if not m:
        raise HTTPException(status_code=500, detail=f"LLMå‡ºåŠ›ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {content_text[:200]}")
    try:
        data = json.loads(m.group(0))
        sql = (data.get("sql") or "").strip()
        if not sql:
            raise ValueError("empty sql")
        return sql
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLM JSON è§£æã«å¤±æ•—: {e}")

_ALLOWED_TABLE_NAMES = set(ALLOWED_TABLES.keys())

def _people_sanitize_sql(sql: str, top_k: int) -> str:
    """
    - å…ˆã«å­˜åœ¨ã—ãªã„åˆ—ã‚’å®‰å…¨ãªåˆ—ã¸æ›¸ãæ›ãˆ
    - ãã®å¾Œã€DML/DDL/UNION/CTE/ã‚µãƒ–ã‚¯ã‚¨ãƒªç¦æ­¢ ãªã©ã‚’æ¤œæŸ»
    - LIMIT ã‚’å¼·åˆ¶
    """
    s = sql.strip().rstrip(";")

    # â˜…â˜…â˜… ã“ã“ã‚’è¿½åŠ ï¼šå­˜åœ¨ã—ãªã„åˆ—ã‚’å¼·åˆ¶ãƒªãƒ©ã‚¤ãƒˆï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ï¼‰
    s = _re.sub(r"\bbc\.title\b", "bc.position", s, flags=_re.I)
    s = _re.sub(r"\bbc\.avatar_url\b", "NULL",        s, flags=_re.I)

    # ä»¥é™ã¯ä»Šã®ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã®ã¾ã¾ï¼ˆOnly single SELECT, (selectâ€¦)/exists/in(select) ç¦æ­¢ ãªã©ï¼‰
    low_raw = s.lower()
    banned_regexes = [
        r";", r"\binsert\b", r"\bupdate\b", r"\bdelete\b",
        r"\bdrop\b", r"\balter\b", r"\bcreate\b", r"\bgrant\b", r"\brevoke\b", r"\btruncate\b",
        r"\bunion\b", r"\bwith\b",
        r"\bin\s*\(\s*select\b", r"\bexists\s*\(", r"\(\s*select\b",
    ]
    for pat in banned_regexes:
        if _re.search(pat, low_raw):
            raise HTTPException(status_code=400, detail="Unsafe SQL is not allowed")

    low = _re.sub(r"\s+", " ", low_raw)

    num_selects = len(_re.findall(r"\bselect\b", low_raw, flags=_re.I))
    if num_selects != 1:
        raise HTTPException(status_code=400, detail="Only a single SELECT is allowed")

    if " from business_cards" not in low:
        raise HTTPException(status_code=400, detail="Root table must be business_cards")

    tables = _re.findall(r"\b(from|join)\s+([a-zA-Z0-9_]+)", low)
    used_tables = {t[1] for t in tables}
    if not used_tables.issubset(_ALLOWED_TABLE_NAMES):
        bad = sorted(list(used_tables - _ALLOWED_TABLE_NAMES))
        raise HTTPException(status_code=400, detail=f"Disallowed tables detected: {bad}")

    if _re.search(r"\blimit\b\s+\d+", s, flags=_re.I):
        s = _re.sub(r"\blimit\b\s+\d+", f"LIMIT {int(top_k)}", s, flags=_re.I)
    else:
        s = s + f" LIMIT {int(top_k)}"

    return s


# â˜… ã“ã“ã«ãƒªãƒˆãƒ©ã‚¤ç”¨ãƒ˜ãƒ«ãƒ‘ã‚’è¿½åŠ 
def _generate_and_sanitize_people_sql(nl_query: str, top_k: int, coworker_id: int | None):
    """
    1å›ç›®: é€šå¸¸ç”Ÿæˆ â†’ ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    2å›ç›®: ã€ŒSELECTã¯1å›ã ã‘ã€ã‚’å¼·åˆ¶ã—ã¦å†ç”Ÿæˆ â†’ ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    3å›ç›®: ã•ã‚‰ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¼·åˆ¶ã§å†ç”Ÿæˆ â†’ ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    ã„ãšã‚Œã‹æˆåŠŸã—ãŸæ®µéšã§è¿”ã™ã€‚ã™ã¹ã¦å¤±æ•—ãªã‚‰æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼ã‚’é€å‡ºã€‚
    """
    attempts = [
        dict(force_single_select=False, force_template=False),
        dict(force_single_select=True,  force_template=False),
        dict(force_single_select=True,  force_template=True),
    ]

    last_err = None
    for i, opt in enumerate(attempts, 1):
        try:
            raw_sql = _people_generate_sql_with_llm(
                nl_query, top_k, coworker_id,
                force_single_select=opt["force_single_select"],
                force_template=opt["force_template"],
            )
            safe_sql = _people_sanitize_sql(raw_sql, top_k)
            if PEOPLE_SQL_DEBUG:
                print(f"[people-sql attempt {i}] OK\nRAW={raw_sql}\nSAFE={safe_sql}")
            return safe_sql, raw_sql
        except HTTPException as e:
            last_err = e
            # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ç”ŸSQLã‚‚å‡ºã™ï¼ˆã‚µãƒ‹ã‚¿ã‚¤ã‚ºå‰ã«è½ã¡ã‚‹ã‚±ãƒ¼ã‚¹ã¯raw_sqlãŒç„¡ã„ã®ã§ç„¡è¦–ï¼‰
            try:
                print(f"[people-sql attempt {i}] FAIL: {e.detail}  (raw maybe above)")
            except Exception:
                pass
            continue

    # 3å›ã¨ã‚‚å¼¾ã‹ã‚ŒãŸ
    if last_err:
        raise last_err
    raise HTTPException(status_code=400, detail="SQL generation failed")

@app.post("/api/people/search")
async def people_search_endpoint(req: PeopleSearchRequest):
    if not (req.query or "").strip():
        return UTF8JSONResponse({"candidates": []})

    eff_coworker_id = req.coworker_id if (req.coworker_id and req.coworker_id > 0) else None

    safe_sql, raw_sql = _generate_and_sanitize_people_sql(
        req.query.strip(), req.top_k, eff_coworker_id
    )

    # å®Ÿè¡Œï¼ˆDB2: junk_dbï¼‰
    try:
        rows = _execute_query_db2(safe_sql, None)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DB error: {e}")

    candidates = []
    for r in rows:
        candidates.append({
            "id": r.get("id"),
            "name": r.get("name"),
            "company": r.get("company") or "",
            "department": r.get("department"),
            "title": r.get("title"),
            "skills": None,
            "avatar_url": r.get("avatar_url"),
            "score": r.get("score") if r.get("score") is not None else 0,
        })

    # 0ä»¶ãªã‚‰ coworkers æ¤œç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not candidates:
        try:
            results = search_coworkers(q=req.query, department="")
            candidates = [{
                "id":         r["id"],
                "name":       r["name"],
                "company":    "",
                "department": r.get("department_name"),
                "title":      r.get("position"),
                "skills":     None,
                "avatar_url": None,
                "score":      0,
            } for r in (results[:req.top_k] if isinstance(results, list) else [])]
        except Exception as ex:
            raise HTTPException(status_code=500, detail=f"coworkers æ¤œç´¢ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ: {ex}") from ex

    res = {"candidates": candidates}
    if PEOPLE_SQL_DEBUG:
        res["debug_sql"] = {"raw": raw_sql, "sanitized": safe_sql}
    return UTF8JSONResponse(res)

# =====================
# People Search (LLMâ†’SQL with JOINs) ã“ã“ã¾ã§
# =====================

# =====================
# (è¿½åŠ ) LLMãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã®äººç‰©æ¢ç´¢ /api/people/ask
# =====================
from pydantic import BaseModel

class PeopleAskRequest(BaseModel):
    """è‡ªç„¶æ–‡ã®è³ªå•ã‹ã‚‰ã€LLMãŒæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç«‹ã¦ã¦äººç‰©å€™è£œã‚’è¿”ã™"""
    question: str
    top_k: int = 5
    coworker_id: int | None = None  # ä»»æ„: è‡ªåˆ†(ã‚„åŒåƒš)IDã‚’å„ªå…ˆåº¦ã®ãƒ’ãƒ³ãƒˆã«ä½¿ã†

class PeopleAskResponse(BaseModel):
    narrative: str                     # LLMãŒè¿”ã™å‰ç½®ããƒ†ã‚­ã‚¹ãƒˆï¼ˆã€Œã“ã†ã„ã†äººã«å½“ãŸã‚Šã¾ã—ã‚‡ã†ã€ãªã©ï¼‰
    queries: list[str]                 # LLMãŒçµ„ã¿ç«‹ã¦ãŸè‡ªç„¶æ–‡ã‚¯ã‚¨ãƒªï¼ˆ/api/people/search ã«ãã®ã¾ã¾æ¸¡ã›ã‚‹ï¼‰
    candidates: list[dict]             # äººç‰©ã‚«ãƒ¼ãƒ‰ï¼ˆid, name, company, department, title, score ãªã©ï¼‰
    # debug: dict | None = None       # å¿…è¦ãªã‚‰ãƒ‡ãƒãƒƒã‚°ã‚‚è¿”ã›ã¾ã™

def _people_search_core(nl_query: str, top_k: int, coworker_id: int | None) -> tuple[list[dict], dict]:
    """
    æ—¢å­˜ã®äººç‰©æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ã‚’é–¢æ•°åŒ–ï¼ˆ/api/people/search ã¨åŒç­‰ï¼‰ã€‚
    è¿”ã‚Šå€¤: (candidates, debug_sql)
    """
    eff_coworker_id = coworker_id if (coworker_id and coworker_id > 0) else None
    safe_sql, raw_sql = _generate_and_sanitize_people_sql(nl_query.strip(), top_k, eff_coworker_id)

    try:
        rows = _execute_query_db2(safe_sql, None)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DB error: {e}")

    candidates: list[dict] = []
    for r in rows:
        candidates.append({
            "id": r.get("id"),
            "name": r.get("name"),
            "company": r.get("company") or "",
            "department": r.get("department"),
            "title": r.get("title"),
            "skills": None,
            "avatar_url": r.get("avatar_url"),
            "score": r.get("score") if r.get("score") is not None else 0,
        })

    # 0ä»¶ãªã‚‰ coworkers ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆæ—¢å­˜ã¨åŒã˜ï¼‰
    if not candidates:
        try:
            results = search_coworkers(q=nl_query, department="")
            candidates = [{
                "id":         r["id"],
                "name":       r["name"],
                "company":    "",
                "department": r.get("department_name"),
                "title":      r.get("position"),
                "skills":     None,
                "avatar_url": None,
                "score":      0,
            } for r in (results[:top_k] if isinstance(results, list) else [])]
        except Exception as ex:
            raise HTTPException(status_code=500, detail=f"coworkers æ¤œç´¢ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ: {ex}") from ex

    debug_sql = {"raw": raw_sql, "sanitized": safe_sql}
    return candidates, debug_sql

def _people_plan_queries(question: str, coworker_id: int | None) -> tuple[str, list[str]]:
    """
    LLMã«ã€Œè³ªå•â†’æœ€å¤§3ã¤ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã€ã¨ã€ŒçŸ­ã„å‰ç½®ãæ–‡ã€ã‚’JSONã§ä½œã‚‰ã›ã‚‹ã€‚
    è¿”ã‚Šå€¤: (narrative, queries)
    """
    if not chat:
        raise HTTPException(status_code=500, detail="OpenAI (chat) ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    hints = []
    if coworker_id is not None and coworker_id > 0:
        hints.append(f"æ‰‹å…ƒã®ååˆºã‚’æŒã£ã¦ã„ã‚‹åŒåƒšIDãŒ {coworker_id} ãªã‚‰ã€ãã®åŒåƒšãŒé–¢ã‚ã£ã¦ã„ãã†ãªå€™è£œã‚’å„ªå…ˆã—ã¦è‰¯ã„ã€‚")

    system = (
        "ã‚ãªãŸã¯ååˆºDBã‹ã‚‰é©åˆ‡ãªäººç‰©ã‚’æ¢ã™ãŸã‚ã®æ¤œç´¢ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶æ–‡ã®è³ªå•ã‚’èª­ã¿å–ã‚Šã€ååˆºDBã«æŠ•ã’ã‚‹æ—¥æœ¬èªã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æœ€å¤§3å€‹ã€ç°¡æ½”ã«ä½œã£ã¦ãã ã•ã„ã€‚"
        "å„ã‚¯ã‚¨ãƒªã¯ã€ä¼šç¤¾å/éƒ¨ç½²/å½¹å‰²/åœ°åŸŸ/ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ãªã©ã‚’å«ã‚€çŸ­æ–‡ã§æ§‹ã„ã¾ã›ã‚“ã€‚"
        "ã¾ãŸã€æœ€åˆã«çŸ­ã„å‰ç½®ãï¼ˆã©ã®ã‚¸ãƒ£ãƒ³ãƒ«ãƒ»ç«‹å ´ã®äººã«å½“ãŸã‚‹ã¹ãã‹ï¼‰ã‚‚ä½œã£ã¦ãã ã•ã„ã€‚"
        "å‡ºåŠ›ã¯å¿…ãš JSON ä¸€å€‹ã®ã¿ã§ã€ä»¥ä¸‹ã®ã‚¹ã‚­ãƒ¼ãƒã«æ­£ç¢ºã«å¾“ã£ã¦ãã ã•ã„ï¼š"
        '{"narrative":"...","queries":["...","..."]}'
    )
    user = (
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {question}\n"
        + (f"ãƒ’ãƒ³ãƒˆ: {', '.join(hints)}\n" if hints else "")
        + "å¿…ãš JSON ã ã‘ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªæ–‡ç« ãƒ»ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã¯ä¸è¦ã§ã™ã€‚"
    )

    resp = chat.invoke([SystemMessage(content=system), HumanMessage(content=user)])
    text = str(resp.content).strip()

    m = re.search(r"\{[\s\S]*\}", text)
    if not m:
        # JSONãŒå–ã‚Œãªã„æ™‚ã¯è³ªå•ãã®ã‚‚ã®ã‚’1ã‚¯ã‚¨ãƒªã«ã™ã‚‹ï¼ˆå‰å‡¦ç†ä»˜ãï¼‰
        return "ä»¥ä¸‹ã®è¦³ç‚¹ã§è©²å½“ã—ãã†ãªäººç‰©ã‚’æ¢ç´¢ã—ã¾ã™ã€‚", [_cleanup_nl_query(question)]

    try:
        data = json.loads(m.group(0))
        narrative = (data.get("narrative") or "").strip() or "ä»¥ä¸‹ã®è¦³ç‚¹ã§è©²å½“ã—ãã†ãªäººç‰©ã‚’æ¢ç´¢ã—ã¾ã™ã€‚"

        # â‘  JSONã‹ã‚‰å–ã‚Šå‡ºã—
        queries = [q for q in (data.get("queries") or []) if isinstance(q, str) and q.strip()]
        if not queries:
            queries = [question]

        # â‘¡ ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
        queries = [_cleanup_nl_query(q) for q in queries]
        queries = [q for q in queries if q] or [_cleanup_nl_query(question)]

        return narrative, queries[:3]
    except Exception:
        # å£Šã‚ŒãŸJSONã§ã‚‚å®‰å…¨ã«
        return "ä»¥ä¸‹ã®è¦³ç‚¹ã§è©²å½“ã—ãã†ãªäººç‰©ã‚’æ¢ç´¢ã—ã¾ã™ã€‚", [_cleanup_nl_query(question)]

@app.post("/api/people/ask", response_model=PeopleAskResponse)
async def people_ask_endpoint(req: PeopleAskRequest):
    """
    ä¾‹ï¼‰{ "question": "å¯Œå±±çœŒã§è¡Œã£ãŸã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«è©³ã—ãã†ãªäººã¯ï¼Ÿ", "top_k": 5 }
    ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼šå‰ç½®ãæ–‡ + LLMãŒç«‹ã¦ãŸã‚¯ã‚¨ãƒªé…åˆ— + ååˆºDBã®å€™è£œ
    """
    if not (req.question or "").strip():
        return UTF8JSONResponse(PeopleAskResponse(narrative="è³ªå•ãŒç©ºã§ã™ã€‚", queries=[], candidates=[]).dict())

    # 1) LLMã§ã‚¯ã‚¨ãƒªè¨ˆç”»
    narrative, queries = _people_plan_queries(req.question.strip(), req.coworker_id)

    # 2) å„ã‚¯ã‚¨ãƒªã‚’äººç‰©æ¤œç´¢ã«ã‹ã‘ã¦é›†ç´„
    all_candidates: dict[int, dict] = {}
    per_query_limit = max(1, req.top_k)  # å„ã‚¯ã‚¨ãƒªã§ååˆ†æ‹¾ã†
    for q in queries:
        try:
            cand, _dbg = _people_search_core(q, per_query_limit, req.coworker_id)
        except HTTPException as e:
            # 1ã‚¯ã‚¨ãƒªå¤±æ•—ã—ã¦ã‚‚ä»–ã‚’ç¶šè¡Œ
            print(f"[people/ask] query failed: {q} -> {e.detail}")
            continue
        for c in cand:
            cid = c.get("id")
            if cid is None:
                continue
            ex = all_candidates.get(cid)
            if ex is None or (c.get("score", 0) > (ex.get("score", 0) or 0)):
                all_candidates[cid] = c

    # 3) ã‚¹ã‚³ã‚¢é †ã«ä¸¦ã¹æ›¿ãˆã¦ä¸Šä½ã‚’è¿”ã™
    merged = sorted(all_candidates.values(), key=lambda x: (x.get("score") or 0, x.get("id") or 0), reverse=True)
    merged = merged[: req.top_k]

    return UTF8JSONResponse(PeopleAskResponse(narrative=narrative, queries=queries, candidates=merged).dict())

# ===== ä¼šç¤¾æƒ…å ± API =====
from pydantic import BaseModel

class CompanyInfo(BaseModel):
    id: int | None = None
    name: str
    corporate_number: str | None = None
    location: str | None = None
    company_type: str | None = None
    founding_date: str | None = None
    capital: str | None = None
    employee_number: int | None = None
    business_summary: str | None = None

class CompanyInfoResponse(BaseModel):
    company: CompanyInfo | None

@app.get("/api/companies/by-name", response_model=CompanyInfoResponse)
async def api_company_by_name(name: str):
    """
    ä¼šç¤¾åã§ 1 ä»¶ã ã‘å–å¾—ã€‚ã¾ãšã¯å®Œå…¨ä¸€è‡´ã€ç„¡ã‘ã‚Œã°ç·©ã‚ã®ä¸€è‡´ã§æ‹¾ã†ã€‚
    å‚ç…§DBã¯ junk_db ã® companiesã€‚
    """
    try:
        sql1 = """
            SELECT id, name, corporate_number, location, company_type,
                   founding_date, capital, employee_number, business_summary
            FROM companies
            WHERE name = %s
            LIMIT 1
        """
        rows = _execute_query_db2(sql1, (name,))
        if not rows:
            # ()/ï¼ˆï¼‰/æ ªå¼ä¼šç¤¾ ã®æºã‚Œã‚’å¸åã—ãŸã‚†ã‚‹ã‚æ¤œç´¢
            sql2 = """
                SELECT id, name, corporate_number, location, company_type,
                       founding_date, capital, employee_number, business_summary
                FROM companies
                WHERE REPLACE(REPLACE(REPLACE(name,'æ ªå¼ä¼šç¤¾',''),'ï¼ˆ','('),'ï¼‰',')')
                      LIKE CONCAT('%', REPLACE(REPLACE(REPLACE(%s,'æ ªå¼ä¼šç¤¾',''),'ï¼ˆ','('),'ï¼‰',')'), '%')
                ORDER BY id ASC
                LIMIT 1
            """
            rows = _execute_query_db2(sql2, (name,))

        if not rows:
            return {"company": None}

        r = rows[0]
        return {
            "company": {
                "id": r.get("id"),
                "name": r.get("name"),
                "corporate_number": r.get("corporate_number"),
                "location": r.get("location"),
                "company_type": r.get("company_type"),
                "founding_date": r.get("founding_date"),
                "capital": r.get("capital"),
                "employee_number": r.get("employee_number"),
                "business_summary": r.get("business_summary"),
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# --- gBizINFO helpers: ã“ã“ã‹ã‚‰è¿½åŠ ï¼ˆ/detail ã®ç›´å‰ã«ç½®ãï¼‰ -----------------
def _fetch_gbiz_by_number(corporate_number: str):
    base = (GBIZINFO_URL or "").rstrip("/") or "https://info.gbiz.go.jp/hojin/v1/hojin"
    url = f"{base}/{corporate_number}"
    resp = requests.get(
        url,
        headers={"X-hojinInfo-api-token": GBIZINFO_API_KEY or "", "accept": "application/json"},
        timeout=10,
    )
    print("[gBizINFO:number]", resp.status_code, url)
    try:
        return resp.status_code, resp.json()
    except Exception:
        return resp.status_code, None

def _fetch_gbiz_by_name(company_name: str):
    # ã–ã£ãã‚Šæ­£è¦åŒ–ï¼ˆã‚†ã‚‰ãå¸åï¼‰
    norm = str(company_name or "").replace("ã€€", " ")
    for t in ("æ ªå¼ä¼šç¤¾", "ï¼ˆæ ªï¼‰", "(æ ª)"):
        norm = norm.replace(t, "")
    norm = norm.strip()

    base = (GBIZINFO_URL or "").rstrip("/") or "https://info.gbiz.go.jp/hojin/v1/hojin"
    from urllib.parse import urlencode
    url = f"{base}?{urlencode({'name': norm})}"
    resp = requests.get(
        url,
        headers={"X-hojinInfo-api-token": GBIZINFO_API_KEY or "", "accept": "application/json"},
        timeout=10,
    )
    print("[gBizINFO:name]", resp.status_code, url)
    try:
        return resp.status_code, resp.json()
    except Exception:
        return resp.status_code, None

def _extract_gbiz_info(payload):
    if not payload:
        return None
    arr = payload.get("hojin-infos") or payload.get("hojinInfos") or []
    if not arr:
        return None
    info = arr[0]
    return {
        "corporate_number": info.get("corporate_number"),
        "name": info.get("name"),
        "location": info.get("location"),
        "postal_code": info.get("postal_code"),
        "company_type": info.get("qualification_grade"),
        "founding_date": info.get("date_of_establishment"),
        "capital": info.get("capital_stock"),
        "employee_number": info.get("employee_number"),
        "business_summary": info.get("business_summary"),
        "update_date": info.get("update_date"),
    }
# --- gBizINFO helpers: ã“ã“ã¾ã§è¿½åŠ  -----------------------------------------

@app.get("/detail/{card_id}")
def get_detail(card_id: int):
    # --- ååˆºæƒ…å ±ï¼ˆMySQL: junk_dbï¼‰ ---
    sql_card = """
        SELECT bc.id, bc.name, bc.company, bc.department, bc.position, bc.memo,
               bc.company_id, c.corporate_number
        FROM business_cards bc
        LEFT JOIN companies c ON bc.company_id = c.id
        WHERE bc.id = %s
    """
    rows = _execute_query_db2(sql_card, (card_id,))
    if not rows:
        raise HTTPException(404, "card not found")
    card = rows[0]

    # --- åŒåƒšï¼ˆåŒã˜ä¼šç¤¾ã®ä»–ã‚«ãƒ¼ãƒ‰ï¼‰ ---
    sql_coworkers = """
        SELECT bc.id, bc.name, bc.department, bc.position
        FROM business_cards bc
        WHERE bc.company_id = %s AND bc.id <> %s
        ORDER BY bc.id
    """
    coworkers = _execute_query_db2(sql_coworkers, (card["company_id"], card_id))

    # --- gBizINFO: â‘ æ³•äººç•ªå· â†’ â‘¡ç¤¾åãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---
    gbiz_info = None
    gbiz_debug = {}
    try:
        corp = str(card.get("corporate_number") or "").strip()
        if not GBIZINFO_API_KEY:
            gbiz_debug["reason"] = "GBIZINFO_API_KEY not set"
        else:
            if corp:
                sc, payload = _fetch_gbiz_by_number(corp)
                gbiz_debug["number_status"] = sc
                gbiz_info = _extract_gbiz_info(payload)

            if not gbiz_info and (card.get("company") or "").strip():
                name = str(card["company"]).strip()
                sc2, payload2 = _fetch_gbiz_by_name(name)
                gbiz_debug["name_status"] = sc2
                gbiz_debug["queried_name"] = name
                gbiz_info = _extract_gbiz_info(payload2)
    except Exception as e:
        print(f"[gBizINFO] error: {e}")
        gbiz_debug["error"] = str(e)

    return {
        "person": card,
        "coworkers": coworkers,
        "gbiz_info": gbiz_info,
        "gbiz_debug": gbiz_debug,   # â† ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ’ãƒ³ãƒˆï¼ˆUIã§ã¯éè¡¨ç¤ºã§ã‚‚OKï¼‰
        "network": _get_network_for_card(card_id),
    }

@app.get("/gbizinfo/detail/{card_id}")
def get_gbizinfo_detail(card_id: int):
    """
    gBizINFO ã®å–å¾—çŠ¶æ³ã ã‘ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®å°‚ç”¨EPã€‚
    è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° 404 ã‚’è¿”ã™ï¼ˆåŸå› åˆ‡ã‚Šåˆ†ã‘ç”¨ï¼‰ã€‚
    """
    sql = """
        SELECT bc.company, c.corporate_number
        FROM business_cards bc
        LEFT JOIN companies c ON bc.company_id = c.id
        WHERE bc.id = %s
    """
    rows = _execute_query_db2(sql, (card_id,))
    if not rows:
        raise HTTPException(404, "card not found")

    corp = str(rows[0].get("corporate_number") or "").strip()
    name = str(rows[0].get("company") or "").strip()

    if not GBIZINFO_API_KEY:
        raise HTTPException(500, "GBIZINFO_API_KEY not set")

    # â‘  æ³•äººç•ªå·
    if corp:
        sc, payload = _fetch_gbiz_by_number(corp)
        info = _extract_gbiz_info(payload)
        if info:
            return {"gbiz_info": info, "via": "number", "status": sc}

    # â‘¡ ç¤¾å
    if name:
        sc2, payload2 = _fetch_gbiz_by_name(name)
        info2 = _extract_gbiz_info(payload2)
        if info2:
            return {"gbiz_info": info2, "via": "name", "status": sc2, "queried_name": name}

    raise HTTPException(404, "gBizINFO not found for this corporate number")

@app.get("/api/coworkers/{coworker_id}/profile")
def get_coworker_profile(coworker_id: int):
    # --- åŸºæœ¬æƒ…å ±ï¼ˆtitleåˆ—â†’ç„¡ã‘ã‚Œã°positionåˆ—ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ---
    sql_basic_title = """
        SELECT cw.id, cw.name, cw.title AS title, d.name AS department
        FROM coworkers cw
        LEFT JOIN departments d ON d.id = cw.department_id
        WHERE cw.id = %s
    """
    sql_basic_position = """
        SELECT cw.id, cw.name, cw.position AS title, d.name AS department
        FROM coworkers cw
        LEFT JOIN departments d ON d.id = cw.department_id
        WHERE cw.id = %s
    """

    try:
        rows = _execute_query_db2(sql_basic_title, (coworker_id,))
    except mysql.connector.errors.ProgrammingError as e:
        # 1054: Unknown column 'cw.title' ã®å ´åˆã¯ position ã§å†å®Ÿè¡Œ
        if "1054" in str(e):
            rows = _execute_query_db2(sql_basic_position, (coworker_id,))
        else:
            raise

    if not rows:
        raise HTTPException(status_code=404, detail="coworker not found")

    basic = rows[0]

    # --- çµŒæ­´ ---
    work_history = []
    for r in _execute_query_db2("""
        SELECT start_year, end_year, company, role, notes
        FROM coworker_experiences
        WHERE coworker_id = %s
        ORDER BY COALESCE(start_year, 0), COALESCE(end_year, 9999)
    """, (coworker_id,)):
        sy = r.get("start_year"); ey = r.get("end_year")
        period = f"{sy or ''}â€“{ey or ''}".strip("â€“")
        text = " / ".join([x for x in [r.get("company"), r.get("role"), r.get("notes")] if x])
        work_history.append({"period": period, "text": text})

    # --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå±¥æ­´ ---
    project_history = []
    for r in _execute_query_db2("""
        SELECT year, title, description
        FROM coworker_projects
        WHERE coworker_id = %s
        ORDER BY COALESCE(year, 0)
    """, (coworker_id,)):
        period = str(r.get("year") or "")
        text = " / ".join([x for x in [r.get("title"), r.get("description")] if x])
        project_history.append({"period": period, "text": text})

    return {
        "id": basic["id"],
        "name": basic["name"],
        "title": basic.get("title"),
        "department": basic.get("department"),
        "work_history": work_history,
        "project_history": project_history,
    }